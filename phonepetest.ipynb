{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7146f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggre_transaction\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "   \n",
    "path=r\"C:/Users/rosha/Downloads/phonepe project/data/aggregated/transaction/country/india/state/\"\n",
    "Agg_tran_list=os.listdir(path)\n",
    "\n",
    "\n",
    "clm={'State':[], 'Year':[],'Quater':[],'Transaction_type':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "for state in Agg_tran_list:\n",
    "    cur_states=path+state+\"/\"\n",
    "    agg_year_list=os.listdir(cur_states)\n",
    "    \n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year=cur_states+year+\"/\"\n",
    "        agg_file_list=os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file=cur_year+file\n",
    "            data=open (cur_file,\"r\")\n",
    "\n",
    "            A=json.load(data)\n",
    "            for i in A[\"data\"][\"transactionData\"]:\n",
    "                name=i[\"name\"]\n",
    "                count=i[\"paymentInstruments\"][0][\"count\"]\n",
    "                amount=i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                clm[\"Transaction_type\"].append(name)\n",
    "                clm[\"Transaction_count\"].append(count)\n",
    "                clm[\"Transaction_amount\"].append(amount)\n",
    "                clm[\"State\"].append(state)\n",
    "                clm[\"Year\"].append(year)\n",
    "                clm[\"Quater\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "Aggre_transaction=pd.DataFrame(clm)\n",
    "Aggre_transaction\n",
    "\n",
    "Aggre_transaction[\"State\"] = Aggre_transaction[\"State\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman and Nicobar\")\n",
    "Aggre_transaction[\"State\"] = Aggre_transaction[\"State\"].str.replace(\"-\",\" \")\n",
    "Aggre_transaction[\"State\"] = Aggre_transaction[\"State\"].str.title()\n",
    "Aggre_transaction[\"State\"] = Aggre_transaction[\"State\"].str.replace(\"dadra-&-nagar-haveli-&-daman-&-diu\",\"Dadra and Nagar Haveli and Daman Diu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dd07235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggre_user\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "path = r\"C:/Users/rosha/Downloads/phonepe project/data/aggregated/user/country/india/state/\"\n",
    "Agg_user_list = os.listdir(path)\n",
    "\n",
    "clm_user = {'State': [], 'Year': [], 'Quater': [], 'Brand': [], 'Count': [], 'Percentage': []}\n",
    "\n",
    "for state in Agg_user_list:\n",
    "    cur_states = path + state + \"/\"\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year = cur_states + year + \"/\"\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file = cur_year + file\n",
    "            data = open(cur_file, \"r\")\n",
    "\n",
    "            A = json.load(data)\n",
    "            # Make sure \"usersByDevice\" exists in the JSON\n",
    "            if A[\"data\"].get(\"usersByDevice\"):\n",
    "                for i in A[\"data\"][\"usersByDevice\"]:\n",
    "                    brand = i[\"brand\"]\n",
    "                    count = i[\"count\"]\n",
    "                    percentage = i[\"percentage\"]\n",
    "                    clm_user[\"Brand\"].append(brand)\n",
    "                    clm_user[\"Count\"].append(count)\n",
    "                    clm_user[\"Percentage\"].append(percentage)\n",
    "                    clm_user[\"State\"].append(state)\n",
    "                    clm_user[\"Year\"].append(year)\n",
    "                    clm_user[\"Quater\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "Aggre_user = pd.DataFrame(clm_user)\n",
    "Aggre_user\n",
    "\n",
    "Aggre_user[\"State\"] = Aggre_user[\"State\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman and Nicobar\")\n",
    "Aggre_user[\"State\"] = Aggre_user[\"State\"].str.replace(\"dadra-&-nagar-haveli-&-daman-&-diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Aggre_user[\"State\"] = Aggre_user[\"State\"].str.replace(\"-\",\" \")\n",
    "Aggre_user[\"State\"] = Aggre_user[\"State\"].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated_insurance\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to aggregated insurance data\n",
    "path =  r\"C:/Users/rosha/Downloads/phonepe project/data/aggregated/insurance/country/india/state/\"\n",
    "Agg_state_list = os.listdir(path)\n",
    "\n",
    "# Create dictionary to store the values\n",
    "clm_insurance = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'Name': [],\n",
    "    'Insurance_Count': [],\n",
    "    'Insurance_Amount': []\n",
    "}\n",
    "\n",
    "# Loop through state -> year -> quarter\n",
    "for i in Agg_state_list:\n",
    "    p_i = path + i + \"/\"\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j = p_i + j + \"/\"\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = p_j + k\n",
    "            with open(p_k, 'r') as Data:\n",
    "                D = json.load(Data)\n",
    "\n",
    "                # Extract data\n",
    "                for z in D['data']['transactionData']:\n",
    "                    clm_insurance['Name'].append(z['name'])\n",
    "                    clm_insurance['Insurance_Count'].append(z['paymentInstruments'][0]['count'])\n",
    "                    clm_insurance['Insurance_Amount'].append(z['paymentInstruments'][0]['amount'])\n",
    "                    clm_insurance['State'].append(i)\n",
    "                    clm_insurance['Year'].append(j)\n",
    "                    clm_insurance['Quarter'].append(int(k.strip('.json')))\n",
    "\n",
    "# Create DataFrame\n",
    "Aggregated_insurance = pd.DataFrame(clm_insurance)\n",
    "Aggregated_insurance\n",
    "\n",
    "Aggregated_insurance[\"State\"] = Aggregated_insurance[\"State\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman and Nicobar\")\n",
    "Aggregated_insurance[\"State\"] = Aggregated_insurance[\"State\"].str.replace(\"dadra-&-nagar-haveli-&-daman-&-diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Aggregated_insurance[\"State\"] = Aggregated_insurance[\"State\"].str.replace(\"-\",\" \")\n",
    "Aggregated_insurance[\"State\"] = Aggregated_insurance[\"State\"].str.title()\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "Aggregated_insurance = pd.DataFrame(clm_insurance)\n",
    "Aggregated_insurance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "868a3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map Hover_transaction\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to map-transaction-hover data  (üìç Windows path)\n",
    "path = r\"C:/Users/rosha/Downloads/phonepe project/data/map/transaction/hover/country/india/state/\"\n",
    "state_list = os.listdir(path)\n",
    "\n",
    "# Create dictionary to store the values\n",
    "clm_hover = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'Transaction_district_name':[],  \n",
    "    'Transaction_count': [],\n",
    "    'Transaction_amount': []\n",
    "}\n",
    "\n",
    "for state in state_list:\n",
    "    cur_states = path + state + \"/\"\n",
    "    year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in year_list:\n",
    "        cur_year = cur_states + year + \"/\"\n",
    "        quarter_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in quarter_list:\n",
    "            cur_file = cur_year + file\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # ‚úÖ paymentInstruments instead of hoverDataList (if needed)\n",
    "            for item in data['data']['hoverDataList']:\n",
    "                hover_state = item['name']\n",
    "                count = item['metric'][0]['count']\n",
    "                amount = item['metric'][0]['amount']\n",
    "\n",
    "                clm_hover['Transaction_district_name'].append(hover_state)\n",
    "                clm_hover['Transaction_count'].append(count)\n",
    "                clm_hover['Transaction_amount'].append(amount)\n",
    "                clm_hover['State'].append(state)\n",
    "                clm_hover['Year'].append(year)\n",
    "                clm_hover['Quarter'].append(int(file.strip('.json')))\n",
    "\n",
    "Hover_transaction = pd.DataFrame(clm_hover)\n",
    "Hover_transaction\n",
    "\n",
    "Hover_transaction[\"State\"] = Hover_transaction[\"State\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman and Nicobar\")\n",
    "Hover_transaction[\"State\"] = Hover_transaction[\"State\"].str.replace(\"dadra-&-nagar-haveli-&-daman-&-diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Hover_transaction[\"State\"] = Hover_transaction[\"State\"].str.replace(\"-\",\" \")\n",
    "Hover_transaction[\"State\"] = Hover_transaction[\"State\"].str.title()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cdfa9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_user/hover\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to map-user hover data\n",
    "path = r\"C:/Users/rosha/Downloads/phonepe project/data/map/user/hover/country/india/state/\"\n",
    "map_user_list = os.listdir(path)\n",
    "\n",
    "# Dictionary to store values\n",
    "clm_user = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'users_district_name': [],\n",
    "    'registeredUsers': [],\n",
    "    'number_appOpens': []\n",
    "}\n",
    "\n",
    "# Loop through all states, years, and quarter files\n",
    "for state in map_user_list:\n",
    "    cur_states = os.path.join(path, state)\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                A = json.load(f)\n",
    "\n",
    "            # Iterate over hoverData dictionary\n",
    "            if A[\"data\"].get(\"hoverData\"):\n",
    "                for district_name, value in A[\"data\"][\"hoverData\"].items():\n",
    "                    registeredUsers = value.get(\"registeredUsers\", 0)\n",
    "                    appOpens = value.get(\"appOpens\", 0)\n",
    "\n",
    "                    clm_user[\"users_district_name\"].append(district_name)\n",
    "                    clm_user[\"registeredUsers\"].append(registeredUsers)\n",
    "                    clm_user[\"number_appOpens\"].append(appOpens)\n",
    "                    clm_user[\"State\"].append(state)\n",
    "                    clm_user[\"Year\"].append(year)\n",
    "                    clm_user[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "# Create DataFrame\n",
    "map_user = pd.DataFrame(clm_user)\n",
    "map_user\n",
    "\n",
    "map_user[\"State\"] = map_user[\"State\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman and Nicobar\")\n",
    "map_user[\"State\"] = map_user[\"State\"].str.replace(\"dadra-&-nagar-haveli-&-daman-&-diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "map_user[\"State\"] = map_user[\"State\"].str.replace(\"-\",\" \")\n",
    "map_user[\"State\"] = map_user[\"State\"].str.title()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463998d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_insurance/hover\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to map-insurance-hover data\n",
    "path = r\"C:/Users/rosha/Downloads/phonepe project/data/map/insurance/hover/country/india/state/\"\n",
    "state_list = os.listdir(path)\n",
    "\n",
    "# Dictionary to store values\n",
    "clm_hover = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'insurance_district_name': [],\n",
    "    'insurance_count': [],\n",
    "    'insurance_amount': []\n",
    "}\n",
    "\n",
    "# Loop through all states, years, and quarter files\n",
    "for state in state_list:\n",
    "    cur_states = os.path.join(path, state)\n",
    "    year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        quarter_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in quarter_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Iterate over hoverDataList\n",
    "            if data['data'].get('hoverDataList'):\n",
    "                for item in data['data']['hoverDataList']:\n",
    "                    district_name = item['name']\n",
    "                    count = item['metric'][0]['count']\n",
    "                    amount = item['metric'][0]['amount']\n",
    "\n",
    "                    clm_hover['insurance_district_name'].append(district_name)\n",
    "                    clm_hover['insurance_count'].append(count)\n",
    "                    clm_hover['insurance_amount'].append(amount)\n",
    "                    clm_hover['State'].append(state)\n",
    "                    clm_hover['Year'].append(year)\n",
    "                    clm_hover['Quarter'].append(int(file.strip('.json')))\n",
    "\n",
    "# Create DataFrame\n",
    "map_insurance = pd.DataFrame(clm_hover)\n",
    "map_insurance\n",
    "\n",
    "map_insurance[\"State\"] = map_insurance[\"State\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman and Nicobar\")\n",
    "map_insurance[\"State\"] = map_insurance[\"State\"].str.replace(\"dadra-&-nagar-haveli-&-daman-&-diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "map_insurance[\"State\"] = map_insurance[\"State\"].str.replace(\"-\",\" \")\n",
    "map_insurance[\"State\"] = map_insurance[\"State\"].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6901a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top/transaction\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to top-transaction data (üìç Windows path)\n",
    "path = r\"C:/Users/rosha/Downloads/phonepe project/data/top/transaction/country/india/state/\"\n",
    "\n",
    "# Create dictionary to store the values\n",
    "clm_top_transaction = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "\n",
    "    'district_entityName': [],\n",
    "    'district_count': [],\n",
    "    'district_amount': [],\n",
    "\n",
    "    'pincode_entityName': [],\n",
    "    'pincode_count': [],\n",
    "    'pincode_amount': []\n",
    "}\n",
    "\n",
    "# Loop through all files\n",
    "state_list = os.listdir(path)\n",
    "\n",
    "for state in state_list:\n",
    "    cur_states = os.path.join(path, state)\n",
    "    year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "      # -- DISTRICTS --\n",
    "            if data[\"data\"].get(\"districts\"):\n",
    "                d = data[\"data\"][\"districts\"][0]\n",
    "                clm_top_transaction[\"district_entityName\"].append(d[\"entityName\"])\n",
    "                clm_top_transaction[\"district_count\"].append(d[\"metric\"][\"count\"])\n",
    "                clm_top_transaction[\"district_amount\"].append(d[\"metric\"][\"amount\"])\n",
    "            else:\n",
    "                clm_top_transaction[\"district_entityName\"].append(None)\n",
    "                clm_top_transaction[\"district_count\"].append(None)\n",
    "                clm_top_transaction[\"district_amount\"].append(None)\n",
    "\n",
    "            # -- PINCODES --\n",
    "            if data[\"data\"].get(\"pincodes\"):\n",
    "                p = data[\"data\"][\"pincodes\"][0]\n",
    "                clm_top_transaction[\"pincode_entityName\"].append(p[\"entityName\"])\n",
    "                clm_top_transaction[\"pincode_count\"].append(p[\"metric\"][\"count\"])\n",
    "                clm_top_transaction[\"pincode_amount\"].append(p[\"metric\"][\"amount\"])\n",
    "            else:\n",
    "                clm_top_transaction[\"pincode_entityName\"].append(None)\n",
    "                clm_top_transaction[\"pincode_count\"].append(None)\n",
    "                clm_top_transaction[\"pincode_amount\"].append(None)\n",
    "\n",
    "            # Common details\n",
    "            clm_top_transaction[\"State\"].append(state)\n",
    "            clm_top_transaction[\"Year\"].append(year)\n",
    "            clm_top_transaction[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "# Create dataframe\n",
    "Top_transaction_df = pd.DataFrame(clm_top_transaction)\n",
    "Top_transaction_df\n",
    "\n",
    "Top_transaction_df[\"State\"] = Top_transaction_df[\"State\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman and Nicobar\")\n",
    "Top_transaction_df[\"State\"] = Top_transaction_df[\"State\"].str.replace(\"dadra-&-nagar-haveli-&-daman-&-diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Top_transaction_df[\"State\"] = Top_transaction_df[\"State\"].str.replace(\"-\",\" \")\n",
    "Top_transaction_df[\"State\"] = Top_transaction_df[\"State\"].str.title()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92542815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top_Users\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to top-user data (üìç Windows path)\n",
    "path = r\"C:/Users/rosha/Downloads/phonepe project/data/top/user/country/india/state/\"\n",
    "\n",
    "# Create dictionary to store the values\n",
    "clm_top_user = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "\n",
    "\n",
    "    'district_name': [],\n",
    "    'district_registeredUsers': [],\n",
    "\n",
    "    'pincode_name': [],\n",
    "    'pincode_registeredUsers': []\n",
    "}\n",
    "\n",
    "# Loop through all files\n",
    "state_list = os.listdir(path)\n",
    "\n",
    "for state in state_list:\n",
    "    cur_states = os.path.join(path, state)\n",
    "    year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # -- DISTRICTS --\n",
    "            if data[\"data\"].get(\"districts\"):\n",
    "                d = data[\"data\"][\"districts\"][0]\n",
    "                clm_top_user[\"district_name\"].append(d[\"name\"])\n",
    "                clm_top_user[\"district_registeredUsers\"].append(d[\"registeredUsers\"])\n",
    "            else:\n",
    "                clm_top_user[\"district_name\"].append(None)\n",
    "                clm_top_user[\"district_registeredUsers\"].append(None)\n",
    "\n",
    "            # -- PINCODES --\n",
    "            if data[\"data\"].get(\"pincodes\"):\n",
    "                p = data[\"data\"][\"pincodes\"][0]\n",
    "                clm_top_user[\"pincode_name\"].append(p[\"name\"])\n",
    "                clm_top_user[\"pincode_registeredUsers\"].append(p[\"registeredUsers\"])\n",
    "            else:\n",
    "                clm_top_user[\"pincode_name\"].append(None)\n",
    "                clm_top_user[\"pincode_registeredUsers\"].append(None)\n",
    "\n",
    "            # Common details\n",
    "            clm_top_user[\"State\"].append(state)\n",
    "            clm_top_user[\"Year\"].append(year)\n",
    "            clm_top_user[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "# Create dataframe\n",
    "Top_user_df = pd.DataFrame(clm_top_user)\n",
    "Top_user_df\n",
    "\n",
    "Top_user_df[\"State\"] = Top_user_df[\"State\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman and Nicobar\")\n",
    "Top_user_df[\"State\"] = Top_user_df[\"State\"].str.replace(\"dadra-&-nagar-haveli-&-daman-&-diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Top_user_df[\"State\"] = Top_user_df[\"State\"].str.replace(\"-\",\" \")\n",
    "Top_user_df[\"State\"] = Top_user_df[\"State\"].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71df192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top/insurance\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to top-insurance data\n",
    "path = r\"C:/Users/rosha/Downloads/phonepe project/data/top/insurance/country/india/state/\"\n",
    "\n",
    "# Dictionary to store values\n",
    "clm_top_insurance = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "\n",
    "    'district_entityName': [],\n",
    "    'district_count': [],\n",
    "    'district_amount': [],\n",
    "\n",
    "    'pincode_entityName': [],\n",
    "    'pincode_count': [],\n",
    "    'pincode_amount': []\n",
    "}\n",
    "\n",
    "# Loop through all files\n",
    "state_list = os.listdir(path)\n",
    "\n",
    "for state in state_list:\n",
    "    cur_states = os.path.join(path, state)\n",
    "    year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "        \n",
    "            # DISTRICTS\n",
    "            if data[\"data\"].get(\"districts\"):\n",
    "                d = data[\"data\"][\"districts\"][0]\n",
    "                clm_top_insurance[\"district_entityName\"].append(d[\"entityName\"])\n",
    "                clm_top_insurance[\"district_count\"].append(d[\"metric\"][\"count\"])\n",
    "                clm_top_insurance[\"district_amount\"].append(d[\"metric\"][\"amount\"])\n",
    "                print(f\"districts ‚Äì {d['entityName']} :‚Äì {d['metric']['count']} :‚Äì {d['metric']['amount']}\")\n",
    "            else:\n",
    "                clm_top_insurance[\"district_entityName\"].append(None)\n",
    "                clm_top_insurance[\"district_count\"].append(None)\n",
    "                clm_top_insurance[\"district_amount\"].append(None)\n",
    "\n",
    "            # PINCODES\n",
    "            if data[\"data\"].get(\"pincodes\"):\n",
    "                p = data[\"data\"][\"pincodes\"][0]\n",
    "                clm_top_insurance[\"pincode_entityName\"].append(p[\"entityName\"])\n",
    "                clm_top_insurance[\"pincode_count\"].append(p[\"metric\"][\"count\"])\n",
    "                clm_top_insurance[\"pincode_amount\"].append(p[\"metric\"][\"amount\"])\n",
    "                print(f\"pincodes ‚Äì {p['entityName']} :‚Äì {p['metric']['count']} :‚Äì {p['metric']['amount']}\")\n",
    "            else:\n",
    "                clm_top_insurance[\"pincode_entityName\"].append(None)\n",
    "                clm_top_insurance[\"pincode_count\"].append(None)\n",
    "                clm_top_insurance[\"pincode_amount\"].append(None)\n",
    "\n",
    "            # Common details\n",
    "            clm_top_insurance[\"State\"].append(state)\n",
    "            clm_top_insurance[\"Year\"].append(year)\n",
    "            clm_top_insurance[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "# Create DataFrame\n",
    "Top_insurance_df = pd.DataFrame(clm_top_insurance)\n",
    "Top_insurance_df\n",
    "\n",
    "Top_insurance_df[\"State\"] = Top_insurance_df[\"State\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman and Nicobar\")\n",
    "Top_insurance_df[\"State\"] = Top_insurance_df[\"State\"].str.replace(\"dadra-&-nagar-haveli-&-daman-&-diu\",\"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "Top_insurance_df[\"State\"] = Top_insurance_df[\"State\"].str.replace(\"-\",\" \")\n",
    "Top_insurance_df[\"State\"] = Top_insurance_df[\"State\"].str.title()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71bfabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install SQLAlchemy PyMySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31062973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ae7a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engine = create_engine(\n",
    "    \"mysql+pymysql://13DQLuf64nn2jC2.root:Yl91nAYMjEKQwgQK@gateway01.ap-southeast-1.prod.aws.tidbcloud.com:4000/phonepe\",\n",
    "    connect_args={\n",
    "        \"ssl\": {\n",
    "            \"ca\": r\"C:\\Users\\rosha\\Downloads\\tidb-ca.pem\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9b9ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5034"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggre_transaction\n",
    "\n",
    "Aggre_transaction.to_sql(\n",
    "    name='Aggre_transaction',\n",
    "    con=engine,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed4a26fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6732"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggre_use''4.png\n",
    "\n",
    "engine.dispose()   \n",
    "\n",
    "Aggre_user.to_sql(\n",
    "    name='Aggre_user',\n",
    "    con=engine,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc175b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggregated_insurance\n",
    "\n",
    "engine.dispose()  \n",
    "\n",
    "Aggregated_insurance.to_sql(\n",
    "    name='Aggre_insurance',\n",
    "    con=engine,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eac25d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20604"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hover_transaction\n",
    "\n",
    "engine.dispose()   \n",
    "\n",
    "Hover_transaction.to_sql(\n",
    "    name='Map_transaction',\n",
    "    con=engine,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c80c34f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20608"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map_user\n",
    "\n",
    "engine.dispose()   \n",
    "map_user.to_sql(\n",
    "    name='Map_user',\n",
    "    con=engine,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd2c9711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13876"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.dispose()\n",
    "\n",
    "map_insurance.to_sql(\n",
    "    name='Map_insurance',\n",
    "    con=engine,\n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e1e178b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top_transaction\n",
    "\n",
    "Top_transaction_df.to_sql(\n",
    "    name='Top_transaction',\n",
    "    con=engine,\n",
    "    if_exists='append',   # or 'replace'\n",
    "    index=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eee0eb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top_user\n",
    "Top_user_df.to_sql(\n",
    "    name='Top_user',\n",
    "    con=engine,\n",
    "    if_exists='append',  \n",
    "    index=False,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9954042c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top_insurance\n",
    "\n",
    "engine.dispose()\n",
    "\n",
    "Top_insurance_df.to_sql(\n",
    "    name='Top_insurance',\n",
    "    con=engine,\n",
    "    if_exists='append',   # or 'replace' if you want to overwrite\n",
    "    index=False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
